# korean-sentiment-analyzer

이전 연구에서 인공지능 모델 구현에서 가장 중요한 단계가 데이터 수집이라는 것을 느낀 바라
자연어 처리에, 특히 이런 다중 분류 같은 경우에는 많은 양의 데이터가 있어야 하므로
직접 데이터 수집에는 어려움을 느끼고 공공 데이터셋을 이용하였다.
 
따라서 데이터셋은 AI Hub에서 제공하는
'한국어 감정 정보가 포함된 단발성 대화 데이터셋' 38,594문장과
연속적 대화 10,000개를 포함하는 '한국어 감정 정보가 포함된 연속적 대화 데이터셋' 55,627문장을 사용하였다.
 
인간의 감정을 단순히 몇 개로 나눌 수 있는 것이 아니라 생각해 감정 분류에도 고민이 있었으나
위 데이터에서 제공하는 분류를 사용하기로 했다.
이 데이터에서는 감정을 중립, 놀람, 분노, 슬픔, 행복, 혐오, 공포 7가지로 분류하고 있다.
 
본 연구의 모든 코드는 Google Colaboratory 환경에서 실행되었다.
 
자연어 처리에서는 모델의 학습보다도 데이터의 전처리 과정이 더 핵심적인 과정이다.
데이터 처리에는 pandas dataframe을 이용하였다.
 
위에서 언급한 데이터셋의 분포를 살펴보면

중립 데이터 48618개, 놀람 데이터 10764개, 분노 데이터 9298개, 슬픔 데이터 7239개, 행복 데이터 7062개, 혐오 데이터 5645개, 공보 데이터 5566개를 포함하고 있다.
데이터 분류 별로 고른 분포를 가지고 있지 않는 것을 보아 추후 연구 결과에 악영향을 미칠 수도 있겠다.
이런 자연어 상태에서는 인공지능 모델을 학습시킬 수 없기에, 데이터를 숫자로 바꿔주어야 한다.
우선 한글을 제외한 특수문자와 기호들을 제거하는 정제 과정을 거친다. (물음표나 느낌표 등의 문장 기호도 감정을 표현할 수 있기에 추후 연구에서는 이 과정을 건너뛰고 연구를 진행해보고 싶은 생각도 있다.)

 
이렇게 정제된 데이터를 토큰으로 나누는 토큰화 작업을 해준다.
토큰화에는 기준에 따른 여러 방법이 있는데,
본 연구에서는 한국어 형태소 분석기 Mecab을 이용해 형태소 단위로 토큰화시켜 주었다.
 

 
이제 토큰을 숫자로 바꾸는 정수 인코딩 작업을 진행하면 전처리는 어느정도 끝이 났다고 보면 된다.
정수 인코딩은 단어당 하나의 정수를 배정받는 식으로 진행된다.
그리고 나서 각 문장을 그 문장을 이루는 단어에 해당하는 숫자들의 나열로 표현하는 것이다.
 
감정 라벨까지 숫자로 표현해주면, 모두 숫자로 이루어진 데이터셋이 완성되어
비로소 인공지능 학습에 적합한 형태가 된다.
 
여기서 한 가지 과정을 더 추가해주자면, 문장들의 길이가 모두 달라 데이터셋의 크기가 모두 다르기 때문에
이 크기를 통일해 주는 것이 좋다.
본 연구에서는 가장 큰 데이터의 크기를 기준으로 0을 추가하는 zero padding 방식을 이용했다.
 

이는 전처리가 완료된 데이터의 예시이다.
 
이제 이 데이터를 train data 80%와 test data 20%로 분리해주었다.
이 데이터를 CNN, LSTM, BiLSTM 3가지 알고리즘을 이용해 딥러닝 모델을 구현했는데,
여기서는 BiLSTM만 언급하고 넘어가겠다.
그 이유는 세 모델의 차이가 크지 않을 뿐더러, 한국어는 단어 앞뒤 양방향의 문맥 파악이 중요하기에
그 중에서 BiLSTM이 가장 적합한 학습 모델이라고 생각했기 때문이다.
 

그렇게 구축한 모델의 구조는 이러하다.
위 모델을 이용해 train data로 학습 후 test data로 정확도를 확인한 결과 약 60.37%의 정확도를 가졌다.
 
사실 심한 과적합 현상이 나타나기는 하였으나 데이터 양의 부족이 큰 부분을 차지한다고 생각하였고
같은 형태를 지닌 데이터를 더 찾기에는 무리라는 생각이 들어 여기서 마무리하였다.
 
하지만 위에서 언급하였던 바와 같이 중립 데이터가 가장 많은 비중을 차지하는 등 데이터의 분포가 고르지 않았고,
데이터에 포함된 문장들을 직접 읽어보면서 '중립'이라는 감정이 굉장히 모호하게 분류가 되었다는 생각이 들었다.
예를 들어 '행복'이나 '분노' 또는 '슬픔'의 경우 해당 감정을 나타내는 단어가 존재한다던가 비교적 명확하다면
중립은 그렇지 않았다.
 
따라서 중립 데이터를 제거하고 나머지 데이터를 이용하여 새롭게 학습시켜 보고 싶다는 생각이 들었다.
 
위 데이터에서 정확히 '중립'만 제거하고 위와 똑같은 구조의 모델에 학습시킨 결과 약 51.97%의 정확도를 얻었다.
오히려 이전보다 정확도가 떨어진 모습이다.
 
이러한 결과가 나온 것에는 언급한대로 기존에 학습 시킨 데이터에 중립 데이터가 큰 비중을 차지하기 때문에,
전체 데이터 중 올바르게 예측한 데이터의 비율을 기준으로 하는 정확도가 높게 나온 것이 아닌가 싶은 생각이 든다.
학습 데이터 중에 많은 비중을 차지했기에 자연스럽게 결과에서도 '중립'이 높은 비중을 차지하게 예측이 될 것이고,
그것이 또다시 높은 확률로 중립 데이터가 맞기 때문에 모델의 성능보다 정확도가 높게 측정된다는 것이다.
 
추후 연구에서는 이 부분을 고려하고, 정확도가 아닌 다른 성능 지표를 이용해 모델을 검증하는 것이 좋을 것 같다.
